{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data_cleaned = train_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values n encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPLG15\\AppData\\Local\\Temp\\ipykernel_14020\\1899511775.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data_cleaned['Age'].fillna(train_data_cleaned['Age'].median(), inplace=True)\n",
      "C:\\Users\\PPLG15\\AppData\\Local\\Temp\\ipykernel_14020\\1899511775.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data_cleaned['Embarked'].fillna(train_data_cleaned['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data_cleaned['Age'].fillna(train_data_cleaned['Age'].median(), inplace=True)\n",
    "train_data_cleaned['Embarked'].fillna(train_data_cleaned['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data_cleaned['Sex'] = label_encoder.fit_transform(train_data_cleaned['Sex'])\n",
    "train_data_cleaned['Embarked'] = label_encoder.fit_transform(train_data_cleaned['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_cleaned.drop('Survived', axis=1)\n",
    "y = train_data_cleaned['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8212290502793296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PPLG15\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:33:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892, 0\n",
      "893, 0\n",
      "894, 0\n",
      "895, 0\n",
      "896, 0\n",
      "897, 0\n",
      "898, 1\n",
      "899, 0\n",
      "900, 1\n",
      "901, 0\n",
      "902, 0\n",
      "903, 0\n",
      "904, 1\n",
      "905, 0\n",
      "906, 1\n",
      "907, 1\n",
      "908, 0\n",
      "909, 0\n",
      "910, 1\n",
      "911, 1\n",
      "912, 0\n",
      "913, 0\n",
      "914, 1\n",
      "915, 0\n",
      "916, 1\n",
      "917, 0\n",
      "918, 1\n",
      "919, 0\n",
      "920, 0\n",
      "921, 0\n",
      "922, 0\n",
      "923, 0\n",
      "924, 1\n",
      "925, 0\n",
      "926, 1\n",
      "927, 0\n",
      "928, 1\n",
      "929, 0\n",
      "930, 0\n",
      "931, 1\n",
      "932, 0\n",
      "933, 1\n",
      "934, 0\n",
      "935, 1\n",
      "936, 1\n",
      "937, 0\n",
      "938, 0\n",
      "939, 0\n",
      "940, 1\n",
      "941, 1\n",
      "942, 0\n",
      "943, 0\n",
      "944, 1\n",
      "945, 1\n",
      "946, 0\n",
      "947, 0\n",
      "948, 0\n",
      "949, 0\n",
      "950, 0\n",
      "951, 1\n",
      "952, 0\n",
      "953, 0\n",
      "954, 0\n",
      "955, 1\n",
      "956, 0\n",
      "957, 1\n",
      "958, 1\n",
      "959, 0\n",
      "960, 0\n",
      "961, 1\n",
      "962, 1\n",
      "963, 0\n",
      "964, 1\n",
      "965, 0\n",
      "966, 1\n",
      "967, 0\n",
      "968, 0\n",
      "969, 1\n",
      "970, 0\n",
      "971, 1\n",
      "972, 1\n",
      "973, 0\n",
      "974, 0\n",
      "975, 0\n",
      "976, 0\n",
      "977, 0\n",
      "978, 1\n",
      "979, 0\n",
      "980, 1\n",
      "981, 1\n",
      "982, 0\n",
      "983, 0\n",
      "984, 1\n",
      "985, 0\n",
      "986, 0\n",
      "987, 0\n",
      "988, 1\n",
      "989, 0\n",
      "990, 0\n",
      "991, 0\n",
      "992, 1\n",
      "993, 0\n",
      "994, 0\n",
      "995, 0\n",
      "996, 1\n",
      "997, 0\n",
      "998, 0\n",
      "999, 0\n",
      "1000, 0\n",
      "1001, 0\n",
      "1002, 0\n",
      "1003, 1\n",
      "1004, 1\n",
      "1005, 1\n",
      "1006, 1\n",
      "1007, 0\n",
      "1008, 0\n",
      "1009, 1\n",
      "1010, 0\n",
      "1011, 1\n",
      "1012, 1\n",
      "1013, 0\n",
      "1014, 1\n",
      "1015, 0\n",
      "1016, 0\n",
      "1017, 1\n",
      "1018, 0\n",
      "1019, 1\n",
      "1020, 0\n",
      "1021, 0\n",
      "1022, 0\n",
      "1023, 0\n",
      "1024, 0\n",
      "1025, 0\n",
      "1026, 0\n",
      "1027, 0\n",
      "1028, 0\n",
      "1029, 0\n",
      "1030, 0\n",
      "1031, 0\n",
      "1032, 0\n",
      "1033, 1\n",
      "1034, 0\n",
      "1035, 0\n",
      "1036, 0\n",
      "1037, 0\n",
      "1038, 0\n",
      "1039, 0\n",
      "1040, 1\n",
      "1041, 0\n",
      "1042, 1\n",
      "1043, 0\n",
      "1044, 0\n",
      "1045, 1\n",
      "1046, 0\n",
      "1047, 0\n",
      "1048, 1\n",
      "1049, 0\n",
      "1050, 0\n",
      "1051, 1\n",
      "1052, 1\n",
      "1053, 1\n",
      "1054, 1\n",
      "1055, 0\n",
      "1056, 0\n",
      "1057, 0\n",
      "1058, 0\n",
      "1059, 0\n",
      "1060, 1\n",
      "1061, 0\n",
      "1062, 0\n",
      "1063, 0\n",
      "1064, 0\n",
      "1065, 0\n",
      "1066, 0\n",
      "1067, 1\n",
      "1068, 1\n",
      "1069, 1\n",
      "1070, 1\n",
      "1071, 1\n",
      "1072, 0\n",
      "1073, 0\n",
      "1074, 1\n",
      "1075, 0\n",
      "1076, 1\n",
      "1077, 0\n",
      "1078, 1\n",
      "1079, 0\n",
      "1080, 0\n",
      "1081, 0\n",
      "1082, 0\n",
      "1083, 0\n",
      "1084, 0\n",
      "1085, 0\n",
      "1086, 1\n",
      "1087, 0\n",
      "1088, 1\n",
      "1089, 0\n",
      "1090, 0\n",
      "1091, 1\n",
      "1092, 1\n",
      "1093, 1\n",
      "1094, 0\n",
      "1095, 1\n",
      "1096, 0\n",
      "1097, 0\n",
      "1098, 1\n",
      "1099, 0\n",
      "1100, 1\n",
      "1101, 0\n",
      "1102, 0\n",
      "1103, 0\n",
      "1104, 0\n",
      "1105, 1\n",
      "1106, 0\n",
      "1107, 0\n",
      "1108, 1\n",
      "1109, 0\n",
      "1110, 1\n",
      "1111, 0\n",
      "1112, 1\n",
      "1113, 0\n",
      "1114, 1\n",
      "1115, 0\n",
      "1116, 1\n",
      "1117, 1\n",
      "1118, 0\n",
      "1119, 1\n",
      "1120, 0\n",
      "1121, 0\n",
      "1122, 0\n",
      "1123, 1\n",
      "1124, 0\n",
      "1125, 0\n",
      "1126, 0\n",
      "1127, 0\n",
      "1128, 0\n",
      "1129, 0\n",
      "1130, 1\n",
      "1131, 1\n",
      "1132, 1\n",
      "1133, 1\n",
      "1134, 0\n",
      "1135, 0\n",
      "1136, 0\n",
      "1137, 0\n",
      "1138, 1\n",
      "1139, 0\n",
      "1140, 1\n",
      "1141, 0\n",
      "1142, 1\n",
      "1143, 0\n",
      "1144, 0\n",
      "1145, 0\n",
      "1146, 0\n",
      "1147, 0\n",
      "1148, 0\n",
      "1149, 0\n",
      "1150, 1\n",
      "1151, 0\n",
      "1152, 0\n",
      "1153, 0\n",
      "1154, 1\n",
      "1155, 1\n",
      "1156, 0\n",
      "1157, 0\n",
      "1158, 0\n",
      "1159, 0\n",
      "1160, 1\n",
      "1161, 0\n",
      "1162, 0\n",
      "1163, 0\n",
      "1164, 1\n",
      "1165, 1\n",
      "1166, 0\n",
      "1167, 1\n",
      "1168, 0\n",
      "1169, 0\n",
      "1170, 0\n",
      "1171, 0\n",
      "1172, 0\n",
      "1173, 1\n",
      "1174, 1\n",
      "1175, 0\n",
      "1176, 1\n",
      "1177, 0\n",
      "1178, 0\n",
      "1179, 0\n",
      "1180, 0\n",
      "1181, 0\n",
      "1182, 0\n",
      "1183, 0\n",
      "1184, 0\n",
      "1185, 0\n",
      "1186, 0\n",
      "1187, 0\n",
      "1188, 1\n",
      "1189, 0\n",
      "1190, 0\n",
      "1191, 0\n",
      "1192, 0\n",
      "1193, 0\n",
      "1194, 0\n",
      "1195, 0\n",
      "1196, 1\n",
      "1197, 1\n",
      "1198, 0\n",
      "1199, 1\n",
      "1200, 0\n",
      "1201, 0\n",
      "1202, 0\n",
      "1203, 0\n",
      "1204, 0\n",
      "1205, 1\n",
      "1206, 1\n",
      "1207, 1\n",
      "1208, 0\n",
      "1209, 0\n",
      "1210, 0\n",
      "1211, 0\n",
      "1212, 0\n",
      "1213, 0\n",
      "1214, 0\n",
      "1215, 0\n",
      "1216, 1\n",
      "1217, 0\n",
      "1218, 1\n",
      "1219, 0\n",
      "1220, 0\n",
      "1221, 0\n",
      "1222, 1\n",
      "1223, 0\n",
      "1224, 0\n",
      "1225, 1\n",
      "1226, 0\n",
      "1227, 0\n",
      "1228, 0\n",
      "1229, 0\n",
      "1230, 0\n",
      "1231, 0\n",
      "1232, 0\n",
      "1233, 0\n",
      "1234, 0\n",
      "1235, 1\n",
      "1236, 0\n",
      "1237, 1\n",
      "1238, 0\n",
      "1239, 1\n",
      "1240, 0\n",
      "1241, 1\n",
      "1242, 1\n",
      "1243, 0\n",
      "1244, 0\n",
      "1245, 0\n",
      "1246, 1\n",
      "1247, 0\n",
      "1248, 1\n",
      "1249, 0\n",
      "1250, 0\n",
      "1251, 1\n",
      "1252, 0\n",
      "1253, 1\n",
      "1254, 1\n",
      "1255, 0\n",
      "1256, 1\n",
      "1257, 0\n",
      "1258, 0\n",
      "1259, 0\n",
      "1260, 1\n",
      "1261, 0\n",
      "1262, 0\n",
      "1263, 1\n",
      "1264, 0\n",
      "1265, 0\n",
      "1266, 1\n",
      "1267, 1\n",
      "1268, 0\n",
      "1269, 0\n",
      "1270, 0\n",
      "1271, 0\n",
      "1272, 0\n",
      "1273, 0\n",
      "1274, 0\n",
      "1275, 1\n",
      "1276, 0\n",
      "1277, 1\n",
      "1278, 0\n",
      "1279, 0\n",
      "1280, 0\n",
      "1281, 0\n",
      "1282, 0\n",
      "1283, 1\n",
      "1284, 0\n",
      "1285, 0\n",
      "1286, 0\n",
      "1287, 1\n",
      "1288, 0\n",
      "1289, 1\n",
      "1290, 0\n",
      "1291, 0\n",
      "1292, 1\n",
      "1293, 0\n",
      "1294, 1\n",
      "1295, 0\n",
      "1296, 0\n",
      "1297, 0\n",
      "1298, 0\n",
      "1299, 0\n",
      "1300, 1\n",
      "1301, 1\n",
      "1302, 1\n",
      "1303, 1\n",
      "1304, 0\n",
      "1305, 0\n",
      "1306, 1\n",
      "1307, 0\n",
      "1308, 0\n",
      "1309, 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPLG15\\AppData\\Local\\Temp\\ipykernel_14020\\3586061346.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data_cleaned['Age'].fillna(test_data_cleaned['Age'].median(), inplace=True)\n",
      "C:\\Users\\PPLG15\\AppData\\Local\\Temp\\ipykernel_14020\\3586061346.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data_cleaned['Embarked'].fillna(test_data_cleaned['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "sex_mapping = {'male': 1, 'female': 0}\n",
    "embarked_mapping = {'S': 2, 'C': 0, 'Q': 1}\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "passenger_ids = test_data['PassengerId']\n",
    "\n",
    "test_data_cleaned = test_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "test_data_cleaned['Age'].fillna(test_data_cleaned['Age'].median(), inplace=True)\n",
    "test_data_cleaned['Embarked'].fillna(test_data_cleaned['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "test_data_cleaned['Sex'] = test_data_cleaned['Sex'].map(sex_mapping)\n",
    "test_data_cleaned['Embarked'] = test_data_cleaned['Embarked'].map(embarked_mapping)\n",
    "\n",
    "predictions = xgb_model.predict(test_data_cleaned)\n",
    "\n",
    "output = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "for index, row in output.iterrows():\n",
    "    print(f\"{row['PassengerId']}, {row['Survived']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test vs Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_survival_proportion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_values \u001b[38;5;241m=\u001b[39m [\u001b[43mtrain_survival_proportion\u001b[49m[\u001b[38;5;241m0\u001b[39m], train_survival_proportion[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      2\u001b[0m test_values \u001b[38;5;241m=\u001b[39m [test_survival_proportion[\u001b[38;5;241m0\u001b[39m], test_survival_proportion[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      4\u001b[0m percentage_similarity \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mabs\u001b[39m(train_values[i] \u001b[38;5;241m-\u001b[39m test_values[i]) \u001b[38;5;241m/\u001b[39m train_values[i]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_values[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_values))\n\u001b[0;32m      7\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_survival_proportion' is not defined"
     ]
    }
   ],
   "source": [
    "train_values = [train_survival_proportion[0], train_survival_proportion[1]]\n",
    "test_values = [test_survival_proportion[0], test_survival_proportion[1]]\n",
    "\n",
    "percentage_similarity = [\n",
    "    (1 - abs(train_values[i] - test_values[i]) / train_values[i]) * 100 if train_values[i] != 0 else 0\n",
    "    for i in range(len(train_values))\n",
    "]\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Percentage similarity for {label}: {percentage_similarity[i]:.2f}%\")\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "rects1 = ax.bar(x - width/2, train_values, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, test_values, width, label='Test')\n",
    "\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Comparison of Survival Proportion: Train vs Test')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3), \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
